# batch_article_generator.py

import os
import dashscope
from http import HTTPStatus
import re
import datetime
import time 
import json 
from typing import List, Dict, Any
import markdown

# ä»ç°æœ‰æ¨¡å—å¯¼å…¥åŠŸèƒ½
from article_writer import generate_article_content
from wanxiangimg import process_article_and_generate_images, generate_image_from_prompt

# --- å…¨å±€é…ç½® ---
# æ³¨æ„ï¼šAPI Key åœ¨ streamlit_app.py ä¸­ç»Ÿä¸€è®¾ç½®ï¼Œè¿™é‡Œæ— éœ€é‡å¤è®¾ç½®
LLM_MODEL_FOR_TITLE_GENERATION = "qwen-turbo" # æŒ‡å®šç”¨äºç”Ÿæˆæ ‡é¢˜çš„æ¨¡å‹

OUTPUT_SAVE_PATH = "generated_output"
# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
if not os.path.exists(OUTPUT_SAVE_PATH):
    os.makedirs(OUTPUT_SAVE_PATH)


# --- å‡½æ•°ï¼šä½¿ç”¨ LLM ç”Ÿæˆæ–‡ç« æ ‡é¢˜åˆ—è¡¨ ---
def generate_article_titles(main_topic: str, num_titles: int, status_callback=None) -> List[str]:
    """
    æ ¹æ®ä¸»è¯¾é¢˜ï¼Œè°ƒç”¨LLMç”ŸæˆæŒ‡å®šæ•°é‡çš„æ–‡ç« æ ‡é¢˜ã€‚
    
    Args:
        main_topic (str): ä¸»è¯¾é¢˜ã€‚
        num_titles (int): éœ€è¦ç”Ÿæˆçš„æ ‡é¢˜æ•°é‡ã€‚
        status_callback (streamlit.status): ç”¨äºåœ¨Streamlit UIä¸­æ›´æ–°çŠ¶æ€ã€‚
        
    Returns:
        List[str]: ç”Ÿæˆçš„æ–‡ç« æ ‡é¢˜åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    print(f"\n--- æ—¥å¿—: å¼€å§‹ä¸ºä¸»é¢˜ '{main_topic}' ç”Ÿæˆæ–‡ç« æ ‡é¢˜ ({num_titles} ä¸ª) ---")
    if status_callback:
        status_callback.update(label=f"ğŸ”„ æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆ {num_titles} ä¸ªæ–‡ç« æ ‡é¢˜...", state="running")

    # ç³»ç»Ÿæç¤ºè¯ï¼šå®šä¹‰LLMçš„è§’è‰²å’Œå†™ä½œé£æ ¼
    system_prompt = ("ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„åˆ›æ„æ ‡é¢˜ç”Ÿæˆå™¨ï¼Œæ“…é•¿ä¸ºç»™å®šä¸»é¢˜ç”Ÿæˆå¤šä¸ªæ–°é¢–ã€å¸å¼•äººä¸”**å…·æœ‰å¼ºçƒˆäººç±»å†™ä½œé£æ ¼**çš„æ–‡ç« æ ‡é¢˜ã€‚ä½ çš„ç›®æ ‡æ˜¯è®©è¯»è€…ä¸€çœ¼å°±è¢«å¸å¼•ï¼Œæ„Ÿè§‰æ˜¯çœŸå®çš„äººåœ¨æ€è€ƒå’Œè¡¨è¾¾ã€‚")
    # ç”¨æˆ·æç¤ºè¯ï¼šåŒ…å«å…·ä½“ä»»åŠ¡å’Œè¦æ±‚
    user_prompt = f"""
    è¯·æ ¹æ®ä»¥ä¸‹ä¸»è¯¾é¢˜ï¼Œç”Ÿæˆ {num_titles} ä¸ªç‹¬ç‰¹çš„ã€å…·æœ‰å¸å¼•åŠ›çš„æ–‡ç« æ ‡é¢˜ã€‚æ¯ä¸ªæ ‡é¢˜åº”è¯¥ç›´æ¥ä½œä¸ºä¸€ç¯‡æ–‡ç« çš„ä¸»é¢˜ã€‚
    ä¸»è¯¾é¢˜: â€œ{main_topic}â€
    **å…³é”®è¦æ±‚ï¼Œè¯·åŠ¡å¿…éµå¾ªï¼Œä»¥ç¡®ä¿æ ‡é¢˜æ›´åƒäººå†™ï¼š**
    1.  **é¿å…**è¿‡äºç”Ÿç¡¬ã€æœºæ¢°æˆ–æ€»ç»“å¼çš„è¡¨è¾¾ã€‚
    2.  **èå…¥**ç–‘é—®ã€åæ€ã€æƒ…æ„Ÿã€è§‚ç‚¹æˆ–å°å°çš„æ‚¬å¿µã€‚
    3.  å¯ä»¥ä½¿ç”¨**æ›´å£è¯­åŒ–ã€æ›´ç”Ÿæ´»åŒ–**çš„è¯æ±‡ï¼Œæˆ–å¼•å‘è¯»è€…å…±é¸£çš„è¡¨è¾¾ã€‚
    4.  æ ‡é¢˜è¦**è¶³å¤Ÿå…·ä½“**ï¼Œå¯ä»¥ç›´æ¥ä½œä¸ºä¸€ç¯‡æ–‡ç« çš„ä¸»é¢˜ï¼Œä½†åˆä¸èƒ½ç¼ºä¹æƒ³è±¡åŠ›ã€‚
    5.  ç¡®ä¿æ ‡é¢˜ä¹‹é—´**å†…å®¹å’Œåˆ‡å…¥ç‚¹æœ‰æ˜æ˜¾å·®å¼‚**ï¼Œé£æ ¼ä¹Ÿå¯ä»¥ç•¥æœ‰ä¸åŒï¼Œä½“ç°å¤šæ ·æ€§ã€‚
    6.  æ¯ä¸ªæ ‡é¢˜ç‹¬å ä¸€è¡Œï¼Œæ ‡é¢˜ä¹‹é—´ä¸è¦æœ‰åºå·æˆ–ä»»ä½•é¢å¤–æ–‡å­—ã€‚
    ä¾‹å¦‚ï¼Œå¦‚æœä¸»é¢˜æ˜¯â€œæ™ºèƒ½å®¶å±…â€ï¼Œä¸è¦åªå†™â€œæ™ºèƒ½å®¶å±…çš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜â€ã€‚å¯ä»¥å°è¯•ï¼š
    - â€œæˆ‘å®¶æ™ºèƒ½éŸ³ç®±çªç„¶â€˜ä¸æƒ³ä¸Šç­â€™äº†ï¼Œæˆ‘è¯¥ç¬‘è¿˜æ˜¯è¯¥å“­ï¼Ÿâ€
    - â€œAIæ­£åœ¨â€˜å·â€™èµ°æˆ‘ä»¬çš„å®¶åŠ¡ï¼Œè¿™æ˜¯å¥½äº‹å—ï¼Ÿâ€
    - â€œä½ å®¶çš„æ™ºèƒ½é—¨é”ï¼ŒçœŸçš„æ¯”ä½ æ›´æ‡‚å®‰å…¨å—ï¼Ÿâ€
    è¯·ä¸¥æ ¼æŒ‰ç…§ç¤ºä¾‹çš„é£æ ¼å’Œè¦æ±‚ç”Ÿæˆï¼š
    """
    messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': user_prompt}]

    try:
        # è°ƒç”¨ DashScope çš„æ–‡æœ¬ç”ŸæˆæœåŠ¡
        response = dashscope.Generation.call(
            model=LLM_MODEL_FOR_TITLE_GENERATION, 
            messages=messages, 
            result_format='message', 
            temperature=1.0, 
            top_p=0.9
        )
        if response.status_code == HTTPStatus.OK:
            titles_raw = response.output.choices[0].message.content.strip()
            titles_list = [t.strip() for t in titles_raw.split('\n') if t.strip()]
            if status_callback:
                status_callback.update(label="âœ… æ–‡ç« æ ‡é¢˜ç”ŸæˆæˆåŠŸï¼", state="running")
            print(f"--- æ—¥å¿—: æ ‡é¢˜ç”ŸæˆæˆåŠŸã€‚å…±ç”Ÿæˆ {len(titles_list)} ä¸ªæ ‡é¢˜ã€‚---")
            print(f"ç”Ÿæˆçš„æ ‡é¢˜åˆ—è¡¨: {titles_list}")
            return titles_list
        else:
            error_msg = f"âŒ æ ‡é¢˜ç”Ÿæˆå¤±è´¥ã€‚çŠ¶æ€ç : {response.status_code}, é”™è¯¯ç : {response.code}, æ¶ˆæ¯: {response.message}"
            if status_callback:
                status_callback.update(label=error_msg, state="error")
            print(f"--- æ—¥å¿—: æ ‡é¢˜ç”Ÿæˆå¤±è´¥ã€‚{error_msg} ---")
            return []
    except Exception as e:
        error_msg = f"âŒ è°ƒç”¨ LLM ç”Ÿæˆæ ‡é¢˜æ—¶å‡ºé”™: {e}"
        if status_callback:
            status_callback.update(label=error_msg, state="error")
        print(f"--- æ—¥å¿—: æ ‡é¢˜ç”Ÿæˆå¼‚å¸¸ã€‚{error_msg} ---")
        return []

# --- å‡½æ•°ï¼šå°†å¤„ç†åçš„JSONæ•°æ®è½¬æ¢ä¸ºHTMLé¡µé¢ ---
def convert_json_to_markdown_to_html(
    title: str,
    processed_data: List[Dict[str, Any]],
    output_filename: str,
    status_callback=None
):
    """
    å°†åŒ…å«æ®µè½å’Œå›¾ç‰‡çš„JSONæ•°æ®ç»“æ„è½¬æ¢ä¸ºä¸€ä¸ªHTMLé¡µé¢ã€‚
    
    Args:
        title (str): æ–‡ç« çš„æ ‡é¢˜ã€‚
        processed_data (List[Dict[str, Any]]): åŒ…å«æ–‡ç« å†…å®¹çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªæ®µè½æˆ–ä¸€å¼ å›¾ç‰‡ã€‚
        output_filename (str): è¾“å‡ºHTMLæ–‡ä»¶çš„æ–‡ä»¶åã€‚
        status_callback (streamlit.status): ç”¨äºåœ¨Streamlit UIä¸­æ›´æ–°çŠ¶æ€ã€‚
    """
    print(f"--- æ—¥å¿—: å¼€å§‹å°†æ–‡ç«  '{title}' è½¬æ¢ä¸º HTML é¡µé¢ ---")
    if status_callback:
        status_callback.update(label="ğŸ“œ æ­£åœ¨å°†JSONæ•°æ®è½¬æ¢ä¸ºMarkdownå¹¶ç”ŸæˆHTML...", state="running")
    
    html_content = f"<h1>{title}</h1>\n\n"
    for item in processed_data:
        if item['type'] == 'paragraph':
            # å°†Markdownæ ¼å¼çš„æ®µè½å†…å®¹è½¬æ¢ä¸ºHTML
            paragraph_html = markdown.markdown(item['content'])
            html_content += paragraph_html
        elif item['type'] == 'image' and item.get('base64_image_data'):
            # å¦‚æœæ˜¯å›¾ç‰‡ï¼Œåˆ™ä½¿ç”¨Base64æ•°æ®åµŒå…¥åˆ°HTMLä¸­
            alt_text = item.get('content', "AIç”Ÿæˆçš„å›¾ç‰‡")
            html_content += f'<img src="{item["base64_image_data"]}" alt="{alt_text}" style="max-width: 100%; height: auto; display: block; margin: 2em auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>\n\n'

    # æ„é€ è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
    output_filepath = os.path.join(OUTPUT_SAVE_PATH, output_filename)
    # å°†ç”Ÿæˆçš„HTMLå†…å®¹å†™å…¥æ–‡ä»¶
    with open(output_filepath, "w", encoding="utf-8") as f:
        f.write(html_content)

    if status_callback:
        status_callback.update(label=f"âœ… HTMLå†…å®¹å·²ç”Ÿæˆåˆ° {output_filepath}", state="running")
    print(f"--- æ—¥å¿—: HTMLå†…å®¹å·²ç”Ÿæˆåˆ° {output_filepath} ---")

# --- ä¸»å‡½æ•°ï¼šæ‰¹é‡ç”Ÿæˆæ–‡ç«  ---
def batch_generate_articles(
    main_topic: str,
    num_articles: int,
    article_gen_params: dict, 
    delay_between_articles: int = 10,
    status_callback=None
):
    """
    æ‰¹é‡ç”Ÿæˆå¤šç¯‡æ–‡ç« ï¼Œå¹¶ä¸ºæ¯ç¯‡æ–‡ç« é…å›¾ã€ç”ŸæˆHTMLã€‚
    
    Args:
        main_topic (str): ä¸»è¯¾é¢˜ã€‚
        num_articles (int): éœ€è¦ç”Ÿæˆçš„æ–‡ç« æ•°é‡ã€‚
        article_gen_params (dict): åŒ…å«æ–‡ç« ç”Ÿæˆç»†èŠ‚å‚æ•°çš„å­—å…¸ã€‚
        delay_between_articles (int): æ¯ç¯‡æ–‡ç« ç”Ÿæˆä¹‹é—´çš„å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        status_callback (streamlit.status): ç”¨äºåœ¨Streamlit UIä¸­æ›´æ–°çŠ¶æ€ã€‚
    """
    print(f"\n--- æ—¥å¿—: æ‰¹é‡ç”Ÿæˆä»»åŠ¡å¼€å§‹ (ä¸»è¯¾é¢˜: {main_topic}, æ•°é‡: {num_articles}) ---")
    if status_callback:
        status_callback.update(label=f"ğŸ¯ æ­£åœ¨ä¸ºä¸»é¢˜ '{main_topic}' å‡†å¤‡ç”Ÿæˆ {num_articles} ç¯‡æ–‡ç« ã€‚", state="running")

    # ç¬¬ä¸€æ­¥ï¼šä¸ºæ‰¹é‡ç”Ÿæˆä»»åŠ¡ç”Ÿæˆæ‰€æœ‰æ–‡ç« æ ‡é¢˜
    article_topics = generate_article_titles(main_topic, num_articles, status_callback=status_callback)
    if not article_topics:
        if status_callback:
            status_callback.update(label="âŒ æœªèƒ½ç”Ÿæˆä»»ä½•æ–‡ç« æ ‡é¢˜ï¼Œæ‰¹é‡ç”Ÿæˆç»ˆæ­¢ã€‚", state="error")
        print("--- æ—¥å¿—: æ‰¹é‡ç”Ÿæˆç»ˆæ­¢ï¼Œæœªç”Ÿæˆä»»ä½•æ ‡é¢˜ã€‚---")
        return
    
    # ä»å‚æ•°å­—å…¸ä¸­æå–æ¨¡å‹ä¿¡æ¯
    llm_model = article_gen_params.get('llm_model', "qwen-plus") 
    image_model = article_gen_params.get('image_model', "wanx-v1") 

    # å¾ªç¯å¤„ç†æ¯ä¸€ç¯‡æ–‡ç« 
    for i, topic in enumerate(article_topics):
        current_article_index = i + 1
        total_articles = len(article_topics)
        print(f"\n--- æ—¥å¿—: å¼€å§‹å¤„ç†ç¬¬ {current_article_index}/{total_articles} ç¯‡æ–‡ç« : '{topic}' ---")
        if status_callback:
            status_callback.update(label=f"æ–‡ç«  {current_article_index}/{total_articles}: æ­£åœ¨å¤„ç† '{topic}'...", state="running")
            
        # æå–æ–‡ç« ç”Ÿæˆå‚æ•°
        current_article_audience = article_gen_params.get('audience', "é€šç”¨è¯»è€…")
        current_article_style = article_gen_params.get('style', "ç§‘æ™®æ€§")
        current_article_length = article_gen_params.get('length', "ä¸­ç¯‡ï¼ˆ600-900å­—ï¼‰")
        current_article_keywords = article_gen_params.get('keywords', [])

        # ç»„åˆé¢å¤–è¦æ±‚å’Œé»˜è®¤è¦æ±‚
        default_extra_requirements = (
            "æ–‡ç« åº”å†…å®¹è‡ªç„¶æµç•…ï¼Œé¿å…AIå†™ä½œçš„ç—•è¿¹ã€‚è¯·ä½¿ç”¨åŠ ç²—æ ‡è®°å¼ºè°ƒæ ¸å¿ƒæ¦‚å¿µã€‚"
            "**å¦‚æœæ–‡ç« åŒ…å«å°æ ‡é¢˜æˆ–å¼ºè°ƒå¥ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨åŒæ˜Ÿå·ï¼ˆ**å†…å®¹**ï¼‰è¿›è¡ŒåŠ ç²—ï¼Œå¹¶ç¡®ä¿å…¶ç‹¬ç«‹æˆè¡Œï¼Œä¸ä¸æ­£æ–‡æ··æ‚åœ¨åŒä¸€è¡Œã€‚**"
            "**é‡è¦æç¤ºï¼šåœ¨æ‚¨è®¤ä¸ºæ–‡ç« çš„æŸä¸ªè‡ªç„¶æ®µè½ç»“æŸåï¼Œæˆ–è€…å½“ä½ è®¤ä¸ºéœ€è¦ä¸€ä¸ªè§†è§‰å…ƒç´ æ¥å¢å¼ºè¯´æ˜æ—¶ï¼Œè¯·åœ¨è¯¥è‡ªç„¶æ®µè½çš„æœ«å°¾å¦èµ·ä¸€è¡Œå¹¶æ’å…¥æ ‡è®° <IMAGE>ã€‚è¯·ç¡®ä¿ <IMAGE> æ˜¯è¯¥è¡Œçš„å”¯ä¸€å†…å®¹ã€‚**"
        )
        user_defined_extra_reqs = article_gen_params.get('extra_requirements', '')
        current_extra_requirements = (user_defined_extra_reqs + "\n\n" + default_extra_requirements).strip()
        current_extra_requirements = re.sub(r'(\*\*é‡è¦æç¤º:.*?<IMAGE>.*?\*\*)\s*\1', r'\1', current_extra_requirements, flags=re.DOTALL)

        # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ–‡ç« å†…å®¹
        if status_callback:
            status_callback.update(label=f"æ–‡ç«  {current_article_index}/{total_articles}: æ­£åœ¨ç”Ÿæˆæ–‡ç« å†…å®¹...", state="running")
        generated_article_content = generate_article_content(
            topic=topic, 
            audience=current_article_audience, 
            style=current_article_style, 
            length=current_article_length,
            keywords=current_article_keywords, 
            extra_requirements=current_extra_requirements,
            model=llm_model, 
            save_to_file=True, 
            status_callback=status_callback
        )
        if not generated_article_content:
            if status_callback:
                status_callback.update(label=f"âŒ æ–‡ç«  {current_article_index}/{total_articles}: æœªèƒ½ç”Ÿæˆå†…å®¹ï¼Œè·³è¿‡ã€‚", state="error")
            print(f"--- æ—¥å¿—: âŒ æœªèƒ½ä¸ºæ–‡ç«  '{topic}' ç”Ÿæˆå†…å®¹ï¼Œè·³è¿‡åç»­æ­¥éª¤ã€‚---")
            continue

        # ç¬¬ä¸‰æ­¥ï¼šå¤„ç†æ–‡ç« å¹¶ç”Ÿæˆå›¾ç‰‡
        if status_callback:
            status_callback.update(label=f"æ–‡ç«  {current_article_index}/{total_articles}: æ­£åœ¨å¤„ç†é…å›¾...", state="running")
        processed_data = process_article_and_generate_images(
            generated_article_content, 
            enable_image_generation=True, 
            image_model=image_model, 
            status_callback=status_callback
        )
        
        # ç¬¬å››æ­¥ï¼šç”ŸæˆHTMLé¡µé¢
        if processed_data:
            # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
            safe_html_filename_base = re.sub(r'[\\/:*?"<>|]', ' ', topic)[:50].strip().replace(' ', '_')
            output_html_filename = f"{safe_html_filename_base}_{current_article_index}_with_ai_images.html"
            convert_json_to_markdown_to_html(
                topic, 
                processed_data, 
                output_html_filename, 
                status_callback=status_callback
            )
            print(f"--- æ—¥å¿—: ç¬¬ {current_article_index} ç¯‡æ–‡ç« å·²å¤„ç†å®Œæ¯•ã€‚---")
        else:
            if status_callback:
                status_callback.update(label=f"âŒ æ–‡ç«  {current_article_index}/{total_articles}: æœªç”Ÿæˆå›¾ç‰‡æ•°æ®ï¼Œæ— æ³•åˆ›å»ºHTMLé¡µé¢ã€‚", state="error")
            print(f"--- æ—¥å¿—: âŒ æœªä¸ºæ–‡ç«  '{topic}' ç”Ÿæˆä»»ä½•å›¾ç‰‡æ•°æ®ï¼Œæ— æ³•åˆ›å»ºHTMLé¡µé¢ã€‚---")

        # ç¬¬äº”æ­¥ï¼šä¿å­˜å¤„ç†åçš„JSONæ•°æ®ï¼ˆå¯é€‰ï¼‰
        safe_json_filename_base = re.sub(r'[\\/:*?"<>|]', ' ', topic)[:50].strip().replace(' ', '_')
        output_json_filename = f"{safe_json_filename_base}_{current_article_index}_results.json"
        output_json_filepath = os.path.join(OUTPUT_SAVE_PATH, output_json_filename)
        with open(output_json_filepath, "w", encoding="utf-8") as f:
            json.dump(processed_data, f, ensure_ascii=False, indent=4)
        if status_callback:
            status_callback.update(label=f"âœ… æ–‡ç«  {current_article_index}/{total_articles}: ç»“æœæ•°æ®å·²ä¿å­˜åˆ° {output_json_filepath}", state="running")
        print(f"--- æ—¥å¿—: ç»“æœæ•°æ®å·²ä¿å­˜åˆ° {output_json_filepath} ---")

        # åœ¨å¤„ç†ä¸‹ä¸€ç¯‡æ–‡ç« ä¹‹å‰è¿›è¡Œå»¶è¿Ÿ
        if i < len(article_topics) - 1:
            print(f"\n--- æ—¥å¿—: æš‚åœ {delay_between_articles} ç§’ï¼Œå‡†å¤‡å¼€å§‹ä¸‹ä¸€ç¯‡æ–‡ç« ... ---")
            if status_callback:
                status_callback.update(label=f"æ–‡ç«  {current_article_index}/{total_articles}: æš‚åœ {delay_between_articles} ç§’ï¼Œå‡†å¤‡ä¸‹ä¸€ç¯‡...", state="running")
            time.sleep(delay_between_articles)

    print("\n--- æ—¥å¿—: æ‰¹é‡ç”Ÿæˆä»»åŠ¡å…¨éƒ¨å®Œæˆã€‚---")

# --- ä¸»æ‰§è¡ŒåŒº (åœ¨æ²¡æœ‰Streamlitè¿è¡Œæ—¶ï¼Œç”¨äºæœ¬åœ°æµ‹è¯•) ---
if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ API Key ç¯å¢ƒå˜é‡ï¼Œå¹¶ä¸”å½“å‰ä¸æ˜¯åœ¨Streamlitä¸­è¿è¡Œ
    if os.environ.get("DASHSCOPE_API_KEY") and os.environ.get("STREAMLIT_RUN", "false").lower() != "true":
        main_batch_topic = "æœªæ¥æ•™è‚²çš„åˆ›æ–°ä¸æŒ‘æˆ˜"
        num_of_articles = 1
        article_generation_parameters = {
            'audience': "æ•™è‚²å·¥ä½œè€…ã€å­¦ç”Ÿå®¶é•¿åŠå¯¹æ•™è‚²æ”¹é©æ„Ÿå…´è¶£çš„å…¬ä¼—", 'style': "æ·±åº¦åˆ†æã€å¯å‘æ€è€ƒï¼Œç•¥å¸¦æœªæ¥ä¸»ä¹‰è‰²å½©",
            'length': "ä¸­ç¯‡ï¼ˆ700-1000å­—ï¼‰", 'keywords': ["æœªæ¥æ•™è‚²", "AIæ•™è‚²", "ä¸ªæ€§åŒ–å­¦ä¹ ", "ç»ˆèº«å­¦ä¹ ", "æ•™è‚²æŠ€æœ¯"],
            'extra_requirements': ("æ–‡ç« åº”æ¢è®¨AIã€è™šæ‹Ÿç°å®ã€ä¸ªæ€§åŒ–å­¦ä¹ åœ¨æœªæ¥æ•™è‚²ä¸­çš„åº”ç”¨ï¼Œä»¥åŠéšä¹‹è€Œæ¥çš„ä¼¦ç†ã€ç¤¾ä¼šæŒ‘æˆ˜ã€‚"
                "å¯ä»¥å¼•ç”¨ä¸€äº›å‡æƒ³çš„æœªæ¥æ•™è‚²åœºæ™¯æˆ–æ¡ˆä¾‹ã€‚" "è¯·ä½¿ç”¨å¼•äººå…¥èƒœçš„è¯­è¨€ã€‚"),
            'llm_model': 'qwen-plus',
            'image_model': 'wanx-v1'
        }
        batch_generate_articles(
            main_batch_topic, num_of_articles, article_generation_parameters, delay_between_articles=15)